{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_05.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZABpep_V-8C"
      },
      "source": [
        "# CUDA Exercise 05\n",
        "> Parallelized Vector add. \n",
        "\n",
        "This Jupyter Notebook can also be open by the google colab, so you don't have to buy a PC with a graphic card to play with CUDA. To launch the Google Colab, please click the below Icon.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/CUDA_Learning/blob/main/Solution/Exercise_05.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P401L2N_WG6R"
      },
      "source": [
        "## Initialize the CUDA dev environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OONoNFZeV63L",
        "outputId": "e15d11f8-6c0f-43b7-b60e-675822ac8794"
      },
      "source": [
        "# clone the code repo,\n",
        "!pip install git+git://github.com/depctg/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "\n",
        "# Check the environment \n",
        "!lsb_release -a\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/depctg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/depctg/nvcc4jupyter.git to /tmp/pip-req-build-2r93udvh\n",
            "  Running command git clone -q git://github.com/depctg/nvcc4jupyter.git /tmp/pip-req-build-2r93udvh\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4334 sha256=4010fe33cb0bdc3a44bc6c4d10aea34076d9daf8c6daec21c1a1544f0ab1b3f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y67t9ubh/wheels/1e/43/2d/099cad2b9b02dfa88573f50a22735d8a0b2ba69bf82167b81c\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "Default out bin result.out\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Thu Apr 22 21:31:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDN2x4izW0rO"
      },
      "source": [
        "## Vector Add with Single Thread"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egrZEZ3MWaP_",
        "outputId": "7d95b219-bf9e-4f5f-e443-e6219f453dd0"
      },
      "source": [
        "%%writefile verctor_add_signal_thread.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define VECTOR_LENGTH 10000 \n",
        "#define MAX_ERR 1e-4\n",
        "\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) \n",
        "{\n",
        "    for(int i = 0; i < n; i++)\n",
        "    {\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out; \n",
        "\n",
        "    // Allocate memory on CPU\n",
        "    a = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    b = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    out = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "\n",
        "    // data initializtion\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++)\n",
        "    {\n",
        "        a[i] = 3.0f;\n",
        "        b[i] = 0.14f;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_a, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_out, sizeof(float) * VECTOR_LENGTH);\n",
        "\n",
        "    // copy operator to GPU\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for(int i=0;i<100;i++)\n",
        "    {\n",
        "      // GPU do the work, CPU waits\n",
        "      vector_add<<<1,1>>>(d_out, d_a, d_b, VECTOR_LENGTH);\n",
        "    }\n",
        "    // Get results from the GPU\n",
        "    cudaMemcpy(out, d_out, sizeof(float) * VECTOR_LENGTH, \n",
        "               cudaMemcpyDeviceToHost);\n",
        " \n",
        "    // Test the result\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++){\n",
        "        assert(fabs(out[i] - a[i] - b[i]) < MAX_ERR);\n",
        "    }\n",
        "    printf(\"out[0] = %f\\n\", out[0]);\n",
        "    printf(\"PASSED\\n\");\n",
        "\n",
        "    // Free the memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing verctor_add_signal_thread.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZI-nXBxefbc"
      },
      "source": [
        "## Vector Add with Multiple Threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxsC_CQRen43",
        "outputId": "184cc2e3-eea7-4731-df27-2fd165c475b6"
      },
      "source": [
        "%%writefile verctor_add_multi_thread.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define VECTOR_LENGTH 10000\n",
        "#define MAX_ERR 1e-4\n",
        "\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) \n",
        "{\n",
        "    int index = threadIdx.x;\n",
        "    int stride = blockDim.x;\n",
        "    for(int i = index; i < n; i=i+stride)\n",
        "    {\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out;\n",
        "    int list_of_test_block_size[]={1,64,128,256,512,1024};\n",
        "    int block_size = 1;\n",
        " \n",
        "    if( argc == 2 ) {\n",
        "      //printf(\"The argument supplied is %s\\n\", argv[1]);\n",
        "      int arg1 = atoi(argv[1]);  //argv[0] is the program name\n",
        "                                //atoi = ascii to int\n",
        "                     \n",
        "      block_size = list_of_test_block_size[arg1];\n",
        "    }\n",
        "    else if( argc > 2 ) {\n",
        "      printf(\"Too many arguments supplied.\\n\");\n",
        "    }\n",
        "    else {\n",
        "      printf(\"One argument expected.\\n\");\n",
        "      \n",
        "    }\n",
        " \n",
        "    printf(\"The Block size is %d.\\n\", block_size);\n",
        "\n",
        "    // Allocate memory on CPU\n",
        "    a = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    b = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    out = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "\n",
        "    // data initializtion\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++)\n",
        "    {\n",
        "        a[i] = 3.0f;\n",
        "        b[i] = 0.14f;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_a, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_out, sizeof(float) * VECTOR_LENGTH);\n",
        "\n",
        "    // copy operator to GPU\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for(int i=0;i<100;i++)\n",
        "    {\n",
        "      // GPU do the work, CPU waits\n",
        "      vector_add<<<1,block_size>>>(d_out, d_a, d_b, VECTOR_LENGTH);\n",
        "    }\n",
        "    // Get results from the GPU\n",
        "    cudaMemcpy(out, d_out, sizeof(float) * VECTOR_LENGTH, \n",
        "               cudaMemcpyDeviceToHost);\n",
        " \n",
        "    // Test the result\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++){\n",
        "        assert(fabs(out[i] - a[i] - b[i]) < MAX_ERR);\n",
        "    }\n",
        "    printf(\"out[0] = %f\\n\", out[0]);\n",
        "    printf(\"PASSED\\n\");\n",
        "\n",
        "    // Free the memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing verctor_add_multi_thread.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Zw1YvsewRK"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4j_yDKhfHzv"
      },
      "source": [
        "Measuring the time cost of executing the CUDA fucntion with **signle thread**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOfZmgUxezqF",
        "outputId": "5be83f69-6a78-4e48-f87e-83b28c36aac1"
      },
      "source": [
        "!nvcc -o verctor_add_signal_thread verctor_add_signal_thread.cu\n",
        "!nvprof ./verctor_add_signal_thread"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==166== NVPROF is profiling process 166, command: ./verctor_add_signal_thread\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==166== Profiling application: ./verctor_add_signal_thread\n",
            "==166== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.99%  118.76ms       100  1.1876ms  1.1875ms  1.1882ms  vector_add(float*, float*, float*, int)\n",
            "                    0.01%  9.6960us         2  4.8480us  4.7040us  4.9920us  [CUDA memcpy HtoD]\n",
            "                    0.00%  5.1840us         1  5.1840us  5.1840us  5.1840us  [CUDA memcpy DtoH]\n",
            "      API calls:   72.18%  312.33ms         3  104.11ms  2.8630us  312.32ms  cudaMalloc\n",
            "                   27.39%  118.53ms         3  39.510ms  27.121us  118.47ms  cudaMemcpy\n",
            "                    0.14%  603.24us         1  603.24us  603.24us  603.24us  cuDeviceGetPCIBusId\n",
            "                    0.11%  481.38us       100  4.8130us  3.4180us  35.589us  cudaLaunchKernel\n",
            "                    0.08%  356.39us         1  356.39us  356.39us  356.39us  cuDeviceTotalMem\n",
            "                    0.04%  182.81us       101  1.8100us     133ns  86.635us  cuDeviceGetAttribute\n",
            "                    0.04%  170.18us         3  56.725us  4.5810us  145.75us  cudaFree\n",
            "                    0.01%  28.980us         1  28.980us  28.980us  28.980us  cuDeviceGetName\n",
            "                    0.00%  1.5750us         2     787ns     328ns  1.2470us  cuDeviceGet\n",
            "                    0.00%  1.4200us         3     473ns     232ns     861ns  cuDeviceGetCount\n",
            "                    0.00%     300ns         1     300ns     300ns     300ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch5mhas6fIZd"
      },
      "source": [
        "Measuring the time cost of executing the CUDA fucntion with **multi-threads**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wc1X6ZCFAVo",
        "outputId": "948c0e1c-a491-4173-9a76-e0bfcb291db5"
      },
      "source": [
        "!nvcc -o verctor_add_multi_thread verctor_add_multi_thread.cu\n",
        "!nvprof ./verctor_add_multi_thread 0\n",
        "!nvprof ./verctor_add_multi_thread 1\n",
        "!nvprof ./verctor_add_multi_thread 2\n",
        "!nvprof ./verctor_add_multi_thread 3\n",
        "!nvprof ./verctor_add_multi_thread 4\n",
        "!nvprof ./verctor_add_multi_thread 5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Block size is 1.\n",
            "==210== NVPROF is profiling process 210, command: ./verctor_add_multi_thread 0\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==210== Profiling application: ./verctor_add_multi_thread 0\n",
            "==210== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.99%  110.00ms       100  1.1000ms  1.0999ms  1.1004ms  vector_add(float*, float*, float*, int)\n",
            "                    0.01%  9.4400us         2  4.7200us  4.5760us  4.8640us  [CUDA memcpy HtoD]\n",
            "                    0.00%  5.1520us         1  5.1520us  5.1520us  5.1520us  [CUDA memcpy DtoH]\n",
            "      API calls:   67.94%  235.85ms         3  78.615ms  2.9820us  235.84ms  cudaMalloc\n",
            "                   31.64%  109.82ms         3  36.607ms  25.740us  109.77ms  cudaMemcpy\n",
            "                    0.15%  533.49us         1  533.49us  533.49us  533.49us  cuDeviceTotalMem\n",
            "                    0.13%  448.80us       100  4.4880us  3.4570us  33.193us  cudaLaunchKernel\n",
            "                    0.07%  230.29us         3  76.761us  5.3020us  199.20us  cudaFree\n",
            "                    0.06%  193.50us       101  1.9150us     184ns  79.100us  cuDeviceGetAttribute\n",
            "                    0.01%  33.101us         1  33.101us  33.101us  33.101us  cuDeviceGetName\n",
            "                    0.00%  5.6790us         1  5.6790us  5.6790us  5.6790us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1510us         3     717ns     201ns  1.4490us  cuDeviceGetCount\n",
            "                    0.00%  1.7380us         2     869ns     272ns  1.4660us  cuDeviceGet\n",
            "                    0.00%     427ns         1     427ns     427ns     427ns  cuDeviceGetUuid\n",
            "The Block size is 64.\n",
            "==221== NVPROF is profiling process 221, command: ./verctor_add_multi_thread 1\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==221== Profiling application: ./verctor_add_multi_thread 1\n",
            "==221== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.66%  3.4722ms       100  34.722us  34.624us  34.945us  vector_add(float*, float*, float*, int)\n",
            "                    0.20%  7.1360us         2  3.5680us  3.4560us  3.6800us  [CUDA memcpy HtoD]\n",
            "                    0.13%  4.5760us         1  4.5760us  4.5760us  4.5760us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.83%  193.30ms         3  64.432ms  3.3410us  193.29ms  cudaMalloc\n",
            "                    1.61%  3.1743ms         3  1.0581ms  24.151us  3.1191ms  cudaMemcpy\n",
            "                    0.24%  475.21us       100  4.7520us  3.4350us  29.099us  cudaLaunchKernel\n",
            "                    0.17%  341.94us         1  341.94us  341.94us  341.94us  cuDeviceTotalMem\n",
            "                    0.07%  145.35us       101  1.4390us     137ns  61.921us  cuDeviceGetAttribute\n",
            "                    0.06%  123.14us         3  41.048us  4.7850us  107.26us  cudaFree\n",
            "                    0.01%  26.334us         1  26.334us  26.334us  26.334us  cuDeviceGetName\n",
            "                    0.00%  5.1070us         1  5.1070us  5.1070us  5.1070us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7040us         2     852ns     311ns  1.3930us  cuDeviceGet\n",
            "                    0.00%  1.5310us         3     510ns     195ns     746ns  cuDeviceGetCount\n",
            "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n",
            "The Block size is 128.\n",
            "==232== NVPROF is profiling process 232, command: ./verctor_add_multi_thread 2\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==232== Profiling application: ./verctor_add_multi_thread 2\n",
            "==232== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.37%  1.8371ms       100  18.371us  18.176us  18.880us  vector_add(float*, float*, float*, int)\n",
            "                    0.39%  7.1360us         2  3.5680us  3.4560us  3.6800us  [CUDA memcpy HtoD]\n",
            "                    0.25%  4.5760us         1  4.5760us  4.5760us  4.5760us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.53%  178.54ms         3  59.513ms  3.2840us  178.53ms  cudaMalloc\n",
            "                    0.85%  1.5462ms         3  515.39us  24.255us  1.4941ms  cudaMemcpy\n",
            "                    0.26%  462.22us       100  4.6220us  3.5560us  25.245us  cudaLaunchKernel\n",
            "                    0.19%  342.18us         1  342.18us  342.18us  342.18us  cuDeviceTotalMem\n",
            "                    0.08%  150.30us       101  1.4880us     137ns  61.771us  cuDeviceGetAttribute\n",
            "                    0.07%  124.56us         3  41.519us  4.7580us  104.88us  cudaFree\n",
            "                    0.01%  27.142us         1  27.142us  27.142us  27.142us  cuDeviceGetName\n",
            "                    0.00%  6.0030us         1  6.0030us  6.0030us  6.0030us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7140us         3     571ns     232ns     991ns  cuDeviceGetCount\n",
            "                    0.00%  1.1770us         2     588ns     302ns     875ns  cuDeviceGet\n",
            "                    0.00%     292ns         1     292ns     292ns     292ns  cuDeviceGetUuid\n",
            "The Block size is 256.\n",
            "==243== NVPROF is profiling process 243, command: ./verctor_add_multi_thread 3\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==243== Profiling application: ./verctor_add_multi_thread 3\n",
            "==243== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   98.87%  1.0244ms       100  10.244us  9.9200us  11.136us  vector_add(float*, float*, float*, int)\n",
            "                    0.69%  7.1360us         2  3.5680us  3.4560us  3.6800us  [CUDA memcpy HtoD]\n",
            "                    0.44%  4.6080us         1  4.6080us  4.6080us  4.6080us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.98%  180.43ms         3  60.143ms  3.3970us  180.42ms  cudaMalloc\n",
            "                    0.38%  692.31us         3  230.77us  23.738us  639.01us  cudaMemcpy\n",
            "                    0.27%  500.12us       100  5.0010us  3.6400us  26.479us  cudaLaunchKernel\n",
            "                    0.20%  367.77us         1  367.77us  367.77us  367.77us  cuDeviceTotalMem\n",
            "                    0.08%  145.39us       101  1.4390us     146ns  60.433us  cuDeviceGetAttribute\n",
            "                    0.07%  121.86us         3  40.621us  4.3540us  106.28us  cudaFree\n",
            "                    0.02%  32.412us         1  32.412us  32.412us  32.412us  cuDeviceGetName\n",
            "                    0.00%  4.7100us         1  4.7100us  4.7100us  4.7100us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4430us         3     481ns     196ns     847ns  cuDeviceGetCount\n",
            "                    0.00%  1.1370us         2     568ns     297ns     840ns  cuDeviceGet\n",
            "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n",
            "The Block size is 512.\n",
            "==256== NVPROF is profiling process 256, command: ./verctor_add_multi_thread 4\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==256== Profiling application: ./verctor_add_multi_thread 4\n",
            "==256== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   98.65%  1.0801ms       100  10.801us  10.592us  11.296us  vector_add(float*, float*, float*, int)\n",
            "                    0.88%  9.6640us         2  4.8320us  4.7040us  4.9600us  [CUDA memcpy HtoD]\n",
            "                    0.46%  5.0880us         1  5.0880us  5.0880us  5.0880us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.92%  184.62ms         3  61.541ms  2.6110us  184.62ms  cudaMalloc\n",
            "                    0.47%  879.32us         3  293.11us  26.589us  797.05us  cudaMemcpy\n",
            "                    0.24%  454.74us       100  4.5470us  3.5170us  30.816us  cudaLaunchKernel\n",
            "                    0.20%  373.11us         1  373.11us  373.11us  373.11us  cuDeviceTotalMem\n",
            "                    0.08%  155.62us       101  1.5400us     139ns  67.367us  cuDeviceGetAttribute\n",
            "                    0.06%  119.57us         3  39.858us  4.2690us  104.01us  cudaFree\n",
            "                    0.02%  29.107us         1  29.107us  29.107us  29.107us  cuDeviceGetName\n",
            "                    0.00%  5.2130us         1  5.2130us  5.2130us  5.2130us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4490us         3     483ns     196ns  1.0070us  cuDeviceGetCount\n",
            "                    0.00%  1.1590us         2     579ns     203ns     956ns  cuDeviceGet\n",
            "                    0.00%     317ns         1     317ns     317ns     317ns  cuDeviceGetUuid\n",
            "The Block size is 1024.\n",
            "==267== NVPROF is profiling process 267, command: ./verctor_add_multi_thread 5\n",
            "out[0] = 3.140000\n",
            "PASSED\n",
            "==267== Profiling application: ./verctor_add_multi_thread 5\n",
            "==267== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   97.97%  715.27us       100  7.1520us  7.0080us  8.0320us  vector_add(float*, float*, float*, int)\n",
            "                    1.33%  9.6960us         2  4.8480us  4.7040us  4.9920us  [CUDA memcpy HtoD]\n",
            "                    0.70%  5.0880us         1  5.0880us  5.0880us  5.0880us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.13%  182.23ms         3  60.744ms  2.6040us  182.22ms  cudaMalloc\n",
            "                    0.29%  528.43us       100  5.2840us  3.5320us  28.747us  cudaLaunchKernel\n",
            "                    0.22%  404.82us         3  134.94us  25.338us  351.20us  cudaMemcpy\n",
            "                    0.20%  358.63us         1  358.63us  358.63us  358.63us  cuDeviceTotalMem\n",
            "                    0.08%  146.85us       101  1.4540us     139ns  62.110us  cuDeviceGetAttribute\n",
            "                    0.07%  122.11us         3  40.701us  4.8210us  105.45us  cudaFree\n",
            "                    0.02%  29.790us         1  29.790us  29.790us  29.790us  cuDeviceGetName\n",
            "                    0.00%  5.5170us         1  5.5170us  5.5170us  5.5170us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.2460us         3     415ns     184ns     737ns  cuDeviceGetCount\n",
            "                    0.00%  1.1670us         2     583ns     223ns     944ns  cuDeviceGet\n",
            "                    0.00%     267ns         1     267ns     267ns     267ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zhihu_02.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZABpep_V-8C"
      },
      "source": [
        "# CUDA Exercise 02\n",
        "> Vector add example with CPU and GPU, only applied with single thread. \n",
        "\n",
        "This Jupyter Notebook can also be open by the google colab, so you don't have to buy a PC with a graphic card to play with CUDA. To launch the Google Colab, please click the below Icon.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/CUDA_Learning/blob/main/Solution/Exercise_02.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P401L2N_WG6R"
      },
      "source": [
        "## Initialize the CUDA dev environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OONoNFZeV63L",
        "outputId": "300c7939-3fac-4eaf-bbfe-1d3641a779f4"
      },
      "source": [
        "# clone the code repo,\n",
        "!pip install git+git://github.com/depctg/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "\n",
        "# Check the environment \n",
        "!lsb_release -a\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/depctg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/depctg/nvcc4jupyter.git to /tmp/pip-req-build-22k37xu7\n",
            "  Running command git clone -q git://github.com/depctg/nvcc4jupyter.git /tmp/pip-req-build-22k37xu7\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4334 sha256=bc12d7017a71a934fd7d39e61241824922d949a1086f514170ffd209c2dc57b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4zyegsxi/wheels/1e/43/2d/099cad2b9b02dfa88573f50a22735d8a0b2ba69bf82167b81c\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "Default out bin result.out\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Thu Apr 22 21:04:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDN2x4izW0rO"
      },
      "source": [
        "## Hello World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "egrZEZ3MWaP_",
        "outputId": "9254f1bb-2518-4300-f124-5754b0674021"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define VECTOR_LENGTH 10000 \n",
        "#define MAX_ERR 1e-4\n",
        "\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) \n",
        "{\n",
        "    for(int i = 0; i < n; i++)\n",
        "    {\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out; \n",
        "\n",
        "    //===================步骤1===================\n",
        "    // Allocate memory on CPU\n",
        "    a = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    b = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "    out = (float*)malloc(sizeof(float) * VECTOR_LENGTH);\n",
        "\n",
        "    // data initializtion\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++)\n",
        "    {\n",
        "        a[i] = 3.0f;\n",
        "        b[i] = 0.14f;\n",
        "    }\n",
        "    //===================步骤1===================\n",
        "\n",
        "    //===================步骤2===================\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_a, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float) * VECTOR_LENGTH);\n",
        "    cudaMalloc((void**)&d_out, sizeof(float) * VECTOR_LENGTH);\n",
        "    //===================步骤2===================\n",
        "\n",
        "    //===================步骤3===================\n",
        "    // copy operator to GPU\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * VECTOR_LENGTH, cudaMemcpyHostToDevice);\n",
        "    //===================步骤3===================\n",
        "\n",
        "    //===================步骤4===================\n",
        "    // GPU do the work, CPU waits\n",
        "    vector_add<<<1,1>>>(d_out, d_a, d_b, VECTOR_LENGTH);\n",
        "    //===================步骤4===================\n",
        "\n",
        "    //===================步骤5===================\n",
        "    // Get results from the GPU\n",
        "    cudaMemcpy(out, d_out, sizeof(float) * VECTOR_LENGTH, \n",
        "               cudaMemcpyDeviceToHost);\n",
        " \n",
        "    // Test the result\n",
        "    for(int i = 0; i < VECTOR_LENGTH; i++)\n",
        "    {\n",
        "        assert(fabs(out[i] - a[i] - b[i]) < MAX_ERR);\n",
        "    }\n",
        "    printf(\"out[0] is %f\\n\", out[0]);\n",
        "    printf(\"PASSED\\n\");\n",
        "    //===================步骤5===================\n",
        "\n",
        "    //===================步骤6===================\n",
        "    // Free the memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "    //===================步骤6===================\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'out[0] is 3.140000\\nPASSED\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}
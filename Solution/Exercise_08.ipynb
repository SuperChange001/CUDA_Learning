{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_08.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-JwSwNW9QmT"
      },
      "source": [
        "\n",
        "# CUDA Exercise 08\n",
        "> You should try to implement your own solution for matrix vector multiplication, and try to parallelize the computation.\n",
        "\n",
        "This Jupyter Notebook can also be open by the google colab, so you don't have to buy a PC with a graphic card to play with CUDA. To launch the Google Colab, please click the below Icon.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/CUDA_Learning/blob/main/Solution/Exercise_08.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOEai4hb95Ip"
      },
      "source": [
        "## Initialize the CUDA dev environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqmwwI7H5nDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7249a7-ed5c-4df7-c209-0a0532f43b66"
      },
      "source": [
        "# clone the code repo,\n",
        "!pip install git+git://github.com/depctg/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/depctg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/depctg/nvcc4jupyter.git to /tmp/pip-req-build-1v8656gq\n",
            "  Running command git clone -q git://github.com/depctg/nvcc4jupyter.git /tmp/pip-req-build-1v8656gq\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4334 sha256=daf9dcf32d16ee5448c7160894af0e19ec99ed00ad1b99b7815f2e5260ead59e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z15lz9io/wheels/1e/43/2d/099cad2b9b02dfa88573f50a22735d8a0b2ba69bf82167b81c\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "Default out bin result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Zeyyo4_gNH"
      },
      "source": [
        "## Check the environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6PT4QpR6oxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a8f3c6-0480-43f5-eb19-11e73f49cff6"
      },
      "source": [
        "!lsb_release -a\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Sun Apr 25 12:09:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF6KTYqE_n7H"
      },
      "source": [
        "## Naive approach of vector dot product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev5_BW1z80S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fb3514-57d7-4095-825b-51f4c3f07063"
      },
      "source": [
        "%%writefile matrix_vector_multiplication.cu\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define M 100\n",
        "#define N 100\n",
        "#define MAX_ERR 1e-4\n",
        "\n",
        "__global__ void matrix_vector_multiplication(float* vector_result, float *matrix_a, float *vector_b, int m_row, int n_col) \n",
        "{\n",
        "    extern __shared__ float temp[];\n",
        " \n",
        "    // blockIdx.x => which row\n",
        "    // blockDim.x => row length\n",
        "    // threadIdx.x => which element in this row\n",
        " \n",
        "    // Unique tid which can index each single element in the matrix\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // the condiction logic make sure, we only do the calculation in the matrix space\n",
        "    int size_of_the_matrix = m_row*n_col;\n",
        "    if(tid<size_of_the_matrix)\n",
        "    {\n",
        "        temp[tid] = matrix_a[tid] * vector_b[threadIdx.x]; // sum\n",
        "    }\n",
        " \n",
        "    __syncthreads(); // synchronize all threads\n",
        " \n",
        "    // The accumulation only needs to happen at thread_0\n",
        "    if (threadIdx.x == 0)\n",
        "    {\n",
        "        float sum = 0;\n",
        "        int index = blockIdx.x * blockDim.x;\n",
        "        for (int i = index; i < index + blockDim.x ; i++)\n",
        "        {\n",
        "            sum += temp[i];\n",
        "        }\n",
        "        vector_result[blockIdx.x] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float *martix_a, *martix_b, *vector_result;\n",
        "    float *d_martix_a, *d_martix_b, *d_vector_result;\n",
        " \n",
        "    martix_a = (float*)malloc(sizeof(float) * (M * N));\n",
        "    martix_b = (float*)malloc(sizeof(float) * (N));\n",
        "    vector_result = (float*)malloc(sizeof(float) * (M));\n",
        "\n",
        "    // data initializtion\n",
        "    for(int raw_num = 0; raw_num < M; raw_num++) \n",
        "    {\n",
        "        for(int col_num = 0; col_num < N; col_num++)\n",
        "        {\n",
        "            int index = raw_num*N+col_num;\n",
        "            martix_a[index] = raw_num*3.14f+col_num;\n",
        "        }\n",
        "    }\n",
        " \n",
        "    for(int col_num = 0; col_num < N; col_num++)\n",
        "    {\n",
        "        martix_b[col_num] = col_num+1;\n",
        "    }\n",
        " \n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_martix_a, sizeof(float) * (M * N));\n",
        "    cudaMalloc((void**)&d_martix_b, sizeof(float) * N);\n",
        "    cudaMalloc((void**)&d_vector_result, sizeof(float) * M);\n",
        "\n",
        "    // copy operator to GPU\n",
        "    cudaMemcpy(d_martix_a, martix_a, sizeof(float) * (M * N), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_martix_b, martix_b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // GPU do the work, CPU waits\n",
        "    matrix_vector_multiplication<<<M,N,sizeof(float) * (M * N)>>>(d_vector_result, d_martix_a, d_martix_b, M, N);\n",
        " \n",
        "    // Get results from the GPU\n",
        "    cudaMemcpy(vector_result, d_vector_result, sizeof(float) * M, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    // Test the result\n",
        "    for(int i = 0; i < M; i++)\n",
        "    {\n",
        "        float temp_sum =0;\n",
        "        for(int j = 0; j < N; j++)\n",
        "        {\n",
        "            int index = i*N+j;\n",
        "            temp_sum = temp_sum + martix_a[index]*martix_b[j]; \n",
        "        }\n",
        "        //printf(\"out[%d]: %f, %f\\n\", i, temp_sum, vector_result[i]);\n",
        "     \n",
        "        assert(fabs(vector_result[i] - temp_sum) < MAX_ERR);\n",
        "    }\n",
        "    printf(\"PASSED\\n\");\n",
        "\n",
        "    // Free the memory\n",
        "    cudaFree(d_martix_a);\n",
        "    cudaFree(d_martix_b);\n",
        "    cudaFree(d_vector_result);\n",
        "    free(martix_a);\n",
        "    free(martix_b);\n",
        "    free(vector_result);\n",
        "    \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing matrix_vector_multiplication.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsEJesxACRz"
      },
      "source": [
        "## Evaluation to collect enough information for the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjisNLsazjUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4cc8a3-1cbc-432f-8a3b-6130ac622b0a"
      },
      "source": [
        "!nvcc -o matrix_vector_multiplication matrix_vector_multiplication.cu\n",
        "!nvprof ./matrix_vector_multiplication 0 0\n",
        "!nvprof ./matrix_vector_multiplication 1 0\n",
        "!nvprof ./matrix_vector_multiplication 2 0\n",
        "!nvprof ./matrix_vector_multiplication 3 0\n",
        "!nvprof ./matrix_vector_multiplication 4 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==163== NVPROF is profiling process 163, command: ./matrix_vector_multiplication 0 0\n",
            "PASSED\n",
            "==163== Profiling application: ./matrix_vector_multiplication 0 0\n",
            "==163== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.83%  9.5680us         1  9.5680us  9.5680us  9.5680us  matrix_vector_multiplication(float*, float*, float*, int, int)\n",
            "                   35.33%  6.3990us         2  3.1990us  1.4400us  4.9590us  [CUDA memcpy HtoD]\n",
            "                   11.84%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.63%  317.36ms         3  105.79ms  3.6120us  317.35ms  cudaMalloc\n",
            "                    0.13%  415.10us         1  415.10us  415.10us  415.10us  cuDeviceGetPCIBusId\n",
            "                    0.11%  343.47us         1  343.47us  343.47us  343.47us  cuDeviceTotalMem\n",
            "                    0.05%  174.52us       101  1.7270us     137ns  77.948us  cuDeviceGetAttribute\n",
            "                    0.04%  116.97us         3  38.988us  4.4090us  102.62us  cudaFree\n",
            "                    0.02%  66.495us         3  22.165us  13.462us  31.317us  cudaMemcpy\n",
            "                    0.01%  32.554us         1  32.554us  32.554us  32.554us  cudaLaunchKernel\n",
            "                    0.01%  27.966us         1  27.966us  27.966us  27.966us  cuDeviceGetName\n",
            "                    0.00%  1.7720us         2     886ns     263ns  1.5090us  cuDeviceGet\n",
            "                    0.00%  1.5290us         3     509ns     218ns     891ns  cuDeviceGetCount\n",
            "                    0.00%     287ns         1     287ns     287ns     287ns  cuDeviceGetUuid\n",
            "==174== NVPROF is profiling process 174, command: ./matrix_vector_multiplication 1 0\n",
            "PASSED\n",
            "==174== Profiling application: ./matrix_vector_multiplication 1 0\n",
            "==174== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   47.77%  9.5680us         1  9.5680us  9.5680us  9.5680us  matrix_vector_multiplication(float*, float*, float*, int, int)\n",
            "                   38.50%  7.7110us         2  3.8550us  2.2400us  5.4710us  [CUDA memcpy HtoD]\n",
            "                   13.74%  2.7520us         1  2.7520us  2.7520us  2.7520us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.54%  182.93ms         3  60.978ms  3.7410us  182.92ms  cudaMalloc\n",
            "                    0.20%  375.54us         1  375.54us  375.54us  375.54us  cuDeviceTotalMem\n",
            "                    0.10%  176.21us       101  1.7440us     140ns  66.739us  cuDeviceGetAttribute\n",
            "                    0.07%  126.33us         3  42.110us  5.3360us  110.48us  cudaFree\n",
            "                    0.05%  98.388us         3  32.796us  17.129us  51.010us  cudaMemcpy\n",
            "                    0.02%  29.650us         1  29.650us  29.650us  29.650us  cuDeviceGetName\n",
            "                    0.02%  29.390us         1  29.390us  29.390us  29.390us  cudaLaunchKernel\n",
            "                    0.00%  5.1810us         1  5.1810us  5.1810us  5.1810us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0550us         3     685ns     251ns  1.3360us  cuDeviceGetCount\n",
            "                    0.00%  1.4870us         2     743ns     217ns  1.2700us  cuDeviceGet\n",
            "                    0.00%     355ns         1     355ns     355ns     355ns  cuDeviceGetUuid\n",
            "==185== NVPROF is profiling process 185, command: ./matrix_vector_multiplication 2 0\n",
            "PASSED\n",
            "==185== Profiling application: ./matrix_vector_multiplication 2 0\n",
            "==185== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.82%  9.6000us         1  9.6000us  9.6000us  9.6000us  matrix_vector_multiplication(float*, float*, float*, int, int)\n",
            "                   35.38%  6.4310us         2  3.2150us  1.4720us  4.9590us  [CUDA memcpy HtoD]\n",
            "                   11.80%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.52%  181.14ms         3  60.380ms  3.7840us  181.13ms  cudaMalloc\n",
            "                    0.22%  408.44us         1  408.44us  408.44us  408.44us  cuDeviceTotalMem\n",
            "                    0.10%  176.51us       101  1.7470us     137ns  74.567us  cuDeviceGetAttribute\n",
            "                    0.08%  137.32us         3  45.772us  4.3090us  123.24us  cudaFree\n",
            "                    0.04%  72.374us         3  24.124us  16.363us  34.360us  cudaMemcpy\n",
            "                    0.02%  45.481us         1  45.481us  45.481us  45.481us  cuDeviceGetName\n",
            "                    0.02%  31.106us         1  31.106us  31.106us  31.106us  cudaLaunchKernel\n",
            "                    0.00%  6.5040us         1  6.5040us  6.5040us  6.5040us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5370us         2     768ns     244ns  1.2930us  cuDeviceGet\n",
            "                    0.00%  1.4890us         3     496ns     183ns     966ns  cuDeviceGetCount\n",
            "                    0.00%     266ns         1     266ns     266ns     266ns  cuDeviceGetUuid\n",
            "==196== NVPROF is profiling process 196, command: ./matrix_vector_multiplication 3 0\n",
            "PASSED\n",
            "==196== Profiling application: ./matrix_vector_multiplication 3 0\n",
            "==196== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.91%  9.6000us         1  9.6000us  9.6000us  9.6000us  matrix_vector_multiplication(float*, float*, float*, int, int)\n",
            "                   35.27%  6.3990us         2  3.1990us  1.4400us  4.9590us  [CUDA memcpy HtoD]\n",
            "                   11.82%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.57%  178.44ms         3  59.480ms  3.7810us  178.43ms  cudaMalloc\n",
            "                    0.20%  354.37us         1  354.37us  354.37us  354.37us  cuDeviceTotalMem\n",
            "                    0.08%  149.41us       101  1.4790us     135ns  64.467us  cuDeviceGetAttribute\n",
            "                    0.06%  113.30us         3  37.767us  4.4850us  98.969us  cudaFree\n",
            "                    0.05%  82.308us         3  27.436us  15.841us  39.855us  cudaMemcpy\n",
            "                    0.02%  31.099us         1  31.099us  31.099us  31.099us  cuDeviceGetName\n",
            "                    0.01%  25.993us         1  25.993us  25.993us  25.993us  cudaLaunchKernel\n",
            "                    0.00%  5.5990us         1  5.5990us  5.5990us  5.5990us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.3730us         3     457ns     201ns     758ns  cuDeviceGetCount\n",
            "                    0.00%  1.2470us         2     623ns     314ns     933ns  cuDeviceGet\n",
            "                    0.00%     298ns         1     298ns     298ns     298ns  cuDeviceGetUuid\n",
            "==207== NVPROF is profiling process 207, command: ./matrix_vector_multiplication 4 0\n",
            "PASSED\n",
            "==207== Profiling application: ./matrix_vector_multiplication 4 0\n",
            "==207== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.75%  9.5360us         1  9.5360us  9.5360us  9.5360us  matrix_vector_multiplication(float*, float*, float*, int, int)\n",
            "                   35.39%  6.3990us         2  3.1990us  1.4400us  4.9590us  [CUDA memcpy HtoD]\n",
            "                   11.86%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.56%  178.76ms         3  59.587ms  3.2190us  178.75ms  cudaMalloc\n",
            "                    0.21%  378.33us         1  378.33us  378.33us  378.33us  cuDeviceTotalMem\n",
            "                    0.09%  165.79us       101  1.6410us     144ns  66.604us  cuDeviceGetAttribute\n",
            "                    0.06%  113.13us         3  37.710us  4.2340us  99.552us  cudaFree\n",
            "                    0.04%  66.321us         3  22.107us  13.131us  32.068us  cudaMemcpy\n",
            "                    0.02%  27.150us         1  27.150us  27.150us  27.150us  cudaLaunchKernel\n",
            "                    0.01%  25.954us         1  25.954us  25.954us  25.954us  cuDeviceGetName\n",
            "                    0.00%  5.6530us         1  5.6530us  5.6530us  5.6530us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1710us         3     723ns     237ns  1.3270us  cuDeviceGetCount\n",
            "                    0.00%  1.3740us         2     687ns     351ns  1.0230us  cuDeviceGet\n",
            "                    0.00%     336ns         1     336ns     336ns     336ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}